{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "\n",
    "\n",
    "from data.dataset import TileDataset, PredictFromImgDataset\n",
    "from data.transforms import HE_preprocess\n",
    "from model_zoo.models import define_model\n",
    "from utils.metrics import dice_scores_img\n",
    "from utils.plots import plot_global_pred, plot_thresh_scores\n",
    "from training.predict import predict_entire_mask\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 256   #the size of tiles\n",
    "reduce_fac = 4 #reduce the original images by 4 times \n",
    "MASKS = '../input/hubmap-kidney-segmentation/train.csv'\n",
    "DATA = '../input/hubmap-kidney-segmentation/train/'\n",
    "ZIP_TRAIN = f'../input/hubmap-kidney-segmentation/train_{tile_size}_red_{reduce_fac}.zip'\n",
    "ZIP_MASKS = f'../input/hubmap-kidney-segmentation/masks_{tile_size}_red_{reduce_fac}.zip'\n",
    "\n",
    "IMG_FOLDER = f'../input/hubmap-kidney-segmentation/train_{tile_size}_red_{reduce_fac}/'\n",
    "MSK_FOLDER = f'../input/hubmap-kidney-segmentation/masks_{tile_size}_red_{reduce_fac}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mask = pd.read_csv(MASKS)\n",
    "slide_ids = df_mask.id.unique().tolist()\n",
    "\n",
    "with zipfile.ZipFile(ZIP_TRAIN, 'r') as img_arch, \\\n",
    "     zipfile.ZipFile(ZIP_MASKS, 'r') as msk_arch:\n",
    "    fnames = img_arch.namelist()\n",
    "    \n",
    "df_images = pd.DataFrame()\n",
    "df_images['tile_name'] = fnames\n",
    "df_images['fold'] = df_images['tile_name'].apply(lambda f: slide_ids.index(f.split(\"_\", 1)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on whole slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained models\n",
    "encoder = \"resnet34\"\n",
    "decoder = \"Unet\"\n",
    "tile_size = 256   #the size of tiles\n",
    "reduce_fac = 4 #reduce the original images by 4 times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_nb in range(8)[::-1]:\n",
    "    model = define_model(decoder, encoder, num_classes=1, activation=None).to(\"cuda\")\n",
    "    model.load_state_dict(torch.load(f\"../models/{encoder}_{decoder}_{tile_size}_{reduce_fac}_fold{fold_nb}.pt\"))\n",
    "    # Here use validation images to visualize fair predictions\n",
    "    maskname = df_images[df_images.fold==fold_nb].tile_name.tolist()[0].split('_', 1)[0]\n",
    "    print(maskname)\n",
    "    predict_dataset = PredictFromImgDataset(f'../input/hubmap-kidney-segmentation/train/{maskname}.tiff',\n",
    "                                            mask_name=maskname,\n",
    "                                            overlap_factor=4,\n",
    "                                            reduce_factor=reduce_fac,\n",
    "                                            transforms=HE_preprocess(augment=False, visualize=False))\n",
    "\n",
    "    global_pred = predict_entire_mask(predict_dataset,\n",
    "                                      model,\n",
    "                                      batch_size=48)\n",
    "    plot_global_pred(mask=predict_dataset.mask, pred=global_pred>0)\n",
    "    thresholds, scores = plot_thresh_scores(mask=predict_dataset.mask, pred=global_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize some results (raw results - not averaged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "BS = 16\n",
    "val_df = df_images[df_images.fold==0].reset_index()\n",
    "val_dataset = TileDataset(val_df,\n",
    "                          IMG_FOLDER, MSK_FOLDER,\n",
    "                          transforms=HE_preprocess(augment=False, visualize=False))\n",
    "\n",
    "preds_dl = DataLoader(val_dataset, batch_size=BS,shuffle=True,num_workers=1)\n",
    "\n",
    "imgs,masks = next(iter(preds_dl))\n",
    "\n",
    "fig = plt.figure(figsize=(8,4*BS))\n",
    "for i,(img,mask) in enumerate(zip(imgs,masks)):\n",
    "    raw_pred = model(img.unsqueeze(0).to('cuda'))\n",
    "    pred = torch.sigmoid(raw_pred) > 0.5\n",
    "    pred = pred.detach().cpu().squeeze().numpy()\n",
    "    plt.subplot(BS, 2, 2*i+1)\n",
    "    img = img.permute(1,2,0).numpy()#.astype(np.uint8)\n",
    "    plt.imshow(img,vmin=0,vmax=255\n",
    "              )\n",
    "    plt.imshow(pred, alpha=0.5)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(BS, 2 ,2*i+2)\n",
    "    plt.imshow(img,vmin=0,vmax=255\n",
    "              )\n",
    "    plt.imshow(mask.squeeze().numpy(), alpha=0.5)\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(wspace=None, hspace=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
