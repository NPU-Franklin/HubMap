{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from https://www.kaggle.com/iafoss/256x256-images\n",
    "\n",
    "You should also launch : `Image downscaling.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append(\"../code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import load_image\n",
    "from utils.rle import *\n",
    "from params import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 256  # the size of tiles\n",
    "reduce = 4  # reduce the original images by 4 times\n",
    "\n",
    "s_th = 20  # saturation blancking threshold\n",
    "p_th = 100 * tile_size // 256  # threshold for the minimum number of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"MASKS = \\\"../input/train.csv\\\"\\nDATA = \\\"../input/train/\\\"\\nOUT_TRAIN = f\\\"../input/train_{tile_size}_red_{reduce}.zip\\\"\\nOUT_MASKS = f\\\"../input/masks_{tile_size}_red_{reduce}.zip\\\"\";\n",
       "                var nbb_formatted_code = \"MASKS = \\\"../input/train.csv\\\"\\nDATA = \\\"../input/train/\\\"\\nOUT_TRAIN = f\\\"../input/train_{tile_size}_red_{reduce}.zip\\\"\\nOUT_MASKS = f\\\"../input/masks_{tile_size}_red_{reduce}.zip\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INPUT_DIR = \"../input/\"\n",
    "MASKS = INPUT_DIR + \"train.csv\"\n",
    "DATA = INPUT_DIR + \"train/\"\n",
    "OUT_TRAIN = INPUT_DIR + f\"train_{tile_size}_red_{reduce}.zip\"\n",
    "OUT_MASKS = INPUT_DIR + f\"masks_{tile_size}_red_{reduce}.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_masks = pd.read_csv(MASKS).set_index(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Zip data\n",
    "- you'll need to unzip the folder manually\n",
    "\n",
    "`unzip /path/to/database.zip -d database`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tot, x2_tot = [], []\n",
    "\n",
    "with zipfile.ZipFile(OUT_TRAIN, \"w\") as img_out, zipfile.ZipFile(\n",
    "    OUT_MASKS, \"w\"\n",
    ") as mask_out:\n",
    "\n",
    "    for index, encs in tqdm(df_masks.iterrows(), total=len(df_masks)):\n",
    "        # read image and generate the mask\n",
    "        img = load_image(os.path.join(DATA, index + \".tiff\"))\n",
    "        mask = enc2mask(encs, (img.shape[1], img.shape[0]))\n",
    "\n",
    "        # add padding to make the image dividable into tiles\n",
    "        shape = img.shape\n",
    "        pad0 = (reduce * tile_size - shape[0] % (reduce * tile_size)) % (\n",
    "            reduce * tile_size\n",
    "        )\n",
    "        pad1 = (reduce * tile_size - shape[1] % (reduce * tile_size)) % (\n",
    "            reduce * tile_size\n",
    "        )\n",
    "        img = np.pad(\n",
    "            img,\n",
    "            [[pad0 // 2, pad0 - pad0 // 2], [pad1 // 2, pad1 - pad1 // 2], [0, 0]],\n",
    "            constant_values=0,\n",
    "        )\n",
    "        mask = np.pad(\n",
    "            mask,\n",
    "            [[pad0 // 2, pad0 - pad0 // 2], [pad1 // 2, pad1 - pad1 // 2]],\n",
    "            constant_values=0,\n",
    "        )\n",
    "\n",
    "        # split image and mask into tiles using the reshape+transpose trick\n",
    "        img = cv2.resize(\n",
    "            img,\n",
    "            (img.shape[1] // reduce, img.shape[0] // reduce),\n",
    "            interpolation=cv2.INTER_AREA,\n",
    "        )\n",
    "        img = img.reshape(\n",
    "            img.shape[0] // tile_size,\n",
    "            tile_size,\n",
    "            img.shape[1] // tile_size,\n",
    "            tile_size,\n",
    "            3,\n",
    "        )\n",
    "        img = img.transpose(0, 2, 1, 3, 4).reshape(-1, tile_size, tile_size, 3)\n",
    "\n",
    "        mask = cv2.resize(\n",
    "            mask,\n",
    "            (mask.shape[1] // reduce, mask.shape[0] // reduce),\n",
    "            interpolation=cv2.INTER_NEAREST,\n",
    "        )\n",
    "        mask = mask.reshape(\n",
    "            mask.shape[0] // tile_size, tile_size, mask.shape[1] // tile_size, tile_size\n",
    "        )\n",
    "        mask = mask.transpose(0, 2, 1, 3).reshape(-1, tile_size, tile_size)\n",
    "\n",
    "        # write data\n",
    "        for tile_num, (im, m) in enumerate(zip(img, mask)):\n",
    "            # remove black or gray images based on saturation check\n",
    "            hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
    "            h, s, v = cv2.split(hsv)\n",
    "            if (s > s_th).sum() <= p_th or im.sum() <= p_th:  # hsv too low\n",
    "                continue\n",
    "\n",
    "            elif ((im.sum(0).sum(-1) == 0).sum() > 1) or ((im.sum(1).sum(-1) == 0).sum() > 1):  # remove padded zones\n",
    "                continue\n",
    "\n",
    "            x_tot.append((im / 255.0).reshape(-1, 3).mean(0))\n",
    "            x2_tot.append(((im / 255.0) ** 2).reshape(-1, 3).mean(0))\n",
    "\n",
    "            im = cv2.imencode(\".png\", cv2.cvtColor(im, cv2.COLOR_RGB2BGR))[1]\n",
    "            img_out.writestr(f\"{index}_{str(tile_num).zfill(5)}.png\", im)\n",
    "            m = cv2.imencode(\".png\", m)[1]\n",
    "            mask_out.writestr(f\"{index}_{str(tile_num).zfill(5)}.png\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_avr = np.array(x_tot).mean(0)\n",
    "img_std = np.sqrt(np.array(x2_tot).mean(0) - img_avr ** 2)\n",
    "print(\"mean:\", img_avr, \", std:\", img_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns, rows = 4, 4\n",
    "idx0 = 8000\n",
    "fig = plt.figure(figsize=(columns * 4, rows * 4))\n",
    "with zipfile.ZipFile(OUT_TRAIN, \"r\") as img_arch, zipfile.ZipFile(\n",
    "    OUT_MASKS, \"r\"\n",
    ") as msk_arch:\n",
    "    fnames = sorted(img_arch.namelist())  # [8:]\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            idx = i + j * columns\n",
    "            img = cv2.imdecode(\n",
    "                np.frombuffer(img_arch.read(fnames[idx0 + idx]), np.uint8),\n",
    "                cv2.IMREAD_COLOR,\n",
    "            )\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            mask = cv2.imdecode(\n",
    "                np.frombuffer(msk_arch.read(fnames[idx0 + idx]), np.uint8),\n",
    "                cv2.IMREAD_GRAYSCALE,\n",
    "            )\n",
    "\n",
    "            fig.add_subplot(rows, columns, idx + 1)\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(Image.fromarray(img))\n",
    "            plt.imshow(Image.fromarray(mask), alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mask = pd.read_csv(DATA_PATH + \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_ids = df_mask.id.unique().tolist()\n",
    "\n",
    "with zipfile.ZipFile(OUT_TRAIN, \"r\") as img_arch, zipfile.ZipFile(\n",
    "    OUT_TRAIN, \"r\"\n",
    ") as msk_arch:\n",
    "    fnames = img_arch.namelist()\n",
    "\n",
    "df_images = pd.DataFrame()\n",
    "df_images[\"tile_name\"] = fnames\n",
    "df_images[\"fold\"] = df_images[\"tile_name\"].apply(\n",
    "    lambda f: slide_ids.index(f.split(\"_\", 1)[0])\n",
    ")\n",
    "\n",
    "df_images[\"5fold\"] = df_images[\"fold\"].apply(lambda x: x % 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images.to_csv(OUT_PATH + \"df_images.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
