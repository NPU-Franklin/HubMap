{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO :**\n",
    "- Recheck Augmentations\n",
    "- Recheck LAB normalization\n",
    "- sampler for faster convergence ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sys.path.append(\"../code/\")\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.main import k_fold\n",
    "\n",
    "from utils.logger import (\n",
    "    prepare_log_folder,\n",
    "    save_config,\n",
    "    create_logger,\n",
    "    update_overall_logs,\n",
    ")\n",
    "\n",
    "from params import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv(DATA_PATH + f\"HuBMAP-20-dataset_information.csv\")\n",
    "df_mask = pd.read_csv(DATA_PATH + \"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = {\n",
    "    \"resnet18\": 64,\n",
    "    \"resnet34\": 32, \n",
    "    \"resnext50_32x4d\": 32, \n",
    "    \"se_resnext50_32x4d\": 32,\n",
    "    \"efficientnet-b1\": 16,\n",
    "    \"efficientnet-b2\": 16,\n",
    "    \"efficientnet-b3\": 16,\n",
    "    \"efficientnet-b4\": 16,\n",
    "    \"efficientnet-b5\": 16,\n",
    "    \"efficientnet-b6\": 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    \n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    save_weights = True\n",
    "    iter_per_epoch = 8000\n",
    "    \n",
    "    # Images\n",
    "    train_tile_size = 256\n",
    "    tile_size = 256\n",
    "    reduce_factor = 4\n",
    "    on_spot_sampling = 0.9\n",
    "    overlap_factor = 2\n",
    "\n",
    "    img_dir = DATA_PATH + f\"train_{train_tile_size}_red_{reduce_factor}\"\n",
    "    mask_dir = DATA_PATH + f\"masks_{train_tile_size}_red_{reduce_factor}\"\n",
    "\n",
    "    # k-fold\n",
    "    cv_column = \"5fold\"\n",
    "    random_state = 0\n",
    "    selected_folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "    # Model\n",
    "    encoder = \"efficientnet-b5\"  # \"resnet18\" \"resnext50_32x4d\", \"resnet34\", \"efficientnet-b5\"\n",
    "    decoder = \"Unet\"  # \"Unet\", \"DeepLabV3Plus\"\n",
    "    model = \"UneXt50_BoT1\"\n",
    "\n",
    "    encoder_weights = \"imagenet\"\n",
    "    num_classes = 1\n",
    "\n",
    "    # Training\n",
    "    loss = \"BCEWithLogitsLoss\"  # \"SoftDiceLoss\" / \"BCEWithLogitsLoss\"  / \"lovasz\"\n",
    "    activation = \"none\" if loss == \"lovasz\" else \"sigmoid\"\n",
    "\n",
    "    optimizer = \"Adam\"\n",
    "    batch_size = BATCH_SIZES[encoder]\n",
    "    \n",
    "    if batch_size >= 32:\n",
    "        epochs = 50\n",
    "    elif batch_size >= 16:\n",
    "        epochs = 40\n",
    "    elif batch_size >= 6:\n",
    "        epochs = 30\n",
    "    else:\n",
    "        epochs = 25\n",
    "\n",
    "    if train_tile_size == 512:\n",
    "        batch_size = batch_size // 4\n",
    "\n",
    "    lr = 1e-3\n",
    "    swa_first_epoch = 50\n",
    "\n",
    "    warmup_prop = 0.05\n",
    "    val_bs = batch_size * 2\n",
    "\n",
    "    first_epoch_eval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(OUT_PATH + f\"df_images_{Config.tile_size}_{Config.reduce_factor}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging results to ../logs/2021-04-01/2/\n",
      "Creating in-memory dataset ...\n"
     ]
    }
   ],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    config_df = save_config(Config, log_folder + \"config.json\")\n",
    "    df.to_csv(log_folder + \"data.csv\", index=False)\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "metrics = k_fold(Config, df, log_folder=log_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
