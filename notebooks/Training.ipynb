{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO :**\n",
    "- Recheck Augmentations\n",
    "- Recheck LAB normalization\n",
    "- sampler for faster convergence ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append(\"../code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from data.transforms import HE_preprocess\n",
    "from data.dataset import TileDataset\n",
    "\n",
    "from model_zoo.models import define_model\n",
    "\n",
    "from training.main import k_fold\n",
    "from utils.logger import (\n",
    "    prepare_log_folder,\n",
    "    save_config,\n",
    "    create_logger,\n",
    "    update_overall_logs,\n",
    ")\n",
    "\n",
    "from utils.plots import plot_contours\n",
    "\n",
    "from params import DATA_PATH, OUT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv(DATA_PATH + f\"HuBMAP-20-dataset_information.csv\")\n",
    "df_mask = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "df = pd.read_csv(OUT_PATH + \"df_images.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = {\n",
    "    \"resnet18\": 64,\n",
    "    \"resnet34\": 32, \n",
    "    \"resnext50_32x4d\": 32, \n",
    "    \"se_resnext50_32x4d\": 32,\n",
    "    \"efficientnet-b4\": 32,\n",
    "    \"efficientnet-b5\": 16,\n",
    "    \"efficientnet-b6\": 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    \n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    img_dir = IMG_PATH\n",
    "    mask_dir = MASK_PATH\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    save_weights = True\n",
    "    iter_per_epoch = 5000 #10000\n",
    "    \n",
    "    # Image size\n",
    "    train_tile_size = 256\n",
    "    reduce_factor = 4\n",
    "    on_spot_sampling = 0.9\n",
    "\n",
    "    # k-fold\n",
    "    cv_column = \"5fold\"\n",
    "    random_state = 0\n",
    "    selected_folds = [0, 1, 2, 3, 4]  # [0]\n",
    "\n",
    "    # Model\n",
    "    encoder = \"efficientnet-b5\"  # \"resnet18\" \"resnext50_32x4d\", \"resnet34\", \"efficientnet-b5\"\n",
    "    decoder = \"Unet\"  # \"Unet\", \"DeepLabV3Plus\"\n",
    "    encoder_weights = \"imagenet\"\n",
    "    num_classes = 1\n",
    "\n",
    "    # Training\n",
    "    loss = \"BCEWithLogitsLoss\"  # \"SoftDiceLoss\" / \"BCEWithLogitsLoss\"  / \"lovasz\"\n",
    "    activation = \"none\" if loss == \"lovasz\" else \"sigmoid\"\n",
    "\n",
    "    optimizer = \"Adam\"\n",
    "    batch_size = BATCH_SIZES[encoder]\n",
    "    \n",
    "         \n",
    "    if batch_size == 32:\n",
    "        epochs = 40\n",
    "    elif batch_size == 16:\n",
    "        epochs = 30\n",
    "    elif batch_size == 8:\n",
    "        epochs = 20\n",
    "        \n",
    "    if train_tile_size == 512:\n",
    "        batch_size = int(batch_size/4)\n",
    "\n",
    "    lr = 1e-3\n",
    "    swa_first_epoch = 50\n",
    "\n",
    "    warmup_prop = 0.05\n",
    "    val_bs = batch_size * 2\n",
    "\n",
    "    first_epoch_eval = 0\n",
    "\n",
    "    # Inference\n",
    "    overlap_factor = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    config_df = save_config(Config, log_folder + \"config.json\")\n",
    "    df.to_csv(log_folder + \"data.csv\", index=False)\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "metrics = k_fold(Config, df, log_folder=log_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
