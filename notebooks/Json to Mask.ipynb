{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import py_wsi\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sys.path.append(\"../code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from utils.rle import *\n",
    "\n",
    "from data.dataset import load_image\n",
    "\n",
    "from utils.metrics import dice_scores_img\n",
    "from utils.plots import plot_heatmap_preds, plot_contours_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv(DATA_PATH + f\"HuBMAP-20-dataset_information.csv\")\n",
    "df_mask = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "\n",
    "ANNOT_PATH = DATA_PATH + \"annotation_v3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False\n",
    "ADD_FC = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73310685af644d55a23ba38336f6dab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> 2f6ecfcdf\n",
      "Added 0 glomerulis\n",
      " -> 8242609fa\n",
      "Added 4 glomerulis\n",
      " -> aaa6a05cc\n",
      "Added 25 glomerulis\n",
      " -> cb2d976f4\n",
      "Added 1 glomerulis\n",
      " -> b9a3865fc\n",
      "Added 4 glomerulis\n",
      " -> b2dc8411c\n",
      "Added 1 glomerulis\n",
      " -> 0486052bb\n",
      " -> e79de561c\n",
      "Added 0 glomerulis\n",
      " -> 095bf7a1f\n",
      "Added 1 glomerulis\n",
      " -> 54f2eec69\n",
      "Added 1 glomerulis\n",
      " -> 4ef6695ce\n",
      "Added 1 glomerulis\n",
      " -> 26dc41664\n",
      " -> c68fe75ea\n",
      "Added 2 glomerulis\n",
      " -> afa5e8098\n",
      "Added 17 glomerulis\n",
      " -> 1e2425f28\n",
      "Added 2 glomerulis\n",
      "\n",
      "\n",
      " -> Saved masks to ../input/train_fc.csv\n"
     ]
    }
   ],
   "source": [
    "new_df = df_mask.copy().set_index('id')\n",
    "\n",
    "for id_ in tqdm(df_mask['id']):\n",
    "    print(f' -> {id_}')\n",
    "    if id_ + \".json\" in os.listdir(ANNOT_PATH):        \n",
    "        annot = json.load(open(ANNOT_PATH + id_ + \".json\", 'r'))\n",
    "        \n",
    "        w, h = df_info[df_info['image_file'] == id_ + '.tiff'][['width_pixels', 'height_pixels']].values[0]\n",
    "        \n",
    "        rle = df_mask[df_mask['id'] == id_]['encoding']\n",
    "        \n",
    "#         mask = enc2mask(rle, (w, h)).astype(np.uint8)  # smh not working\n",
    "        mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        mask += enc2mask(rle, (w, h)).astype(np.uint8)\n",
    "        \n",
    "        added = 0\n",
    "        for info in annot:\n",
    "            label = info['properties']['classification']['name']\n",
    "\n",
    "            if label == \"FC\":\n",
    "                if not ADD_FC or id_ != \"aaa6a05cc\":\n",
    "                    continue\n",
    "\n",
    "            poly = info['geometry']['coordinates']\n",
    "            try:\n",
    "                mask = cv2.fillPoly(mask, np.int32([poly]), True)\n",
    "            except ValueError:\n",
    "                poly = np.concatenate([np.array(poly[i]).squeeze() for i in range(len(poly))])\n",
    "                mask = cv2.fillPoly(mask, np.int32([poly]), True)\n",
    "            added +=1\n",
    "            \n",
    "        print(f\"Added {added} glomerulis\")\n",
    "        \n",
    "        new_df.loc[id_] = rle_encode_less_memory(mask)\n",
    "        \n",
    "        if PLOT:\n",
    "            img = load_image(os.path.join(TIFF_PATH_4, id_ + \".tiff\"), full_size=False)\n",
    "            \n",
    "            mask = cv2.resize(\n",
    "                mask,\n",
    "                (w // 4, h // 4),\n",
    "                interpolation=cv2.INTER_NEAREST,\n",
    "            )\n",
    "            assert mask.shape == img.shape[:2], (mask.shape, img.shape)\n",
    "        \n",
    "            fig = plot_contours_preds(img, mask, w=1, downsize=4)\n",
    "            w = 1000\n",
    "            h = int(w *  mask.shape[0] / mask.shape[1])\n",
    "            fig.update_layout(\n",
    "                autosize=False,\n",
    "                width=w,\n",
    "                height=h,\n",
    "            )\n",
    "\n",
    "            fig.show()\n",
    "\n",
    "            break\n",
    "\n",
    "if not PLOT:\n",
    "    name = \"train_fix.csv\" if not ADD_FC else \"train_fc.csv\"\n",
    "    new_df.to_csv(DATA_PATH + name)\n",
    "    \n",
    "    print(f'\\n -> Saved masks to {DATA_PATH + name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False\n",
    "SAVE_TIFF = False\n",
    "SAVE = True\n",
    "ADD_FC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 WSI found in directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40059f0822e44450a95cbe2958c5bc26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> SESCAM_1_0\n",
      "Setting patch size -1 and tile size -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-a25a191b4ba3>:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  poly = np.array(info['geometry']['coordinates'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 61 glomerulis\n",
      " -> SESCAM_102\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 23 glomerulis\n",
      " -> SAS_21904_001\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 10 glomerulis\n",
      " -> SAS_21908_001\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 7 glomerulis\n",
      " -> VUHSK_1502\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 36 glomerulis\n",
      " -> SESCAM_7_0\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 18 glomerulis\n",
      " -> VUHSK_2072\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 20 glomerulis\n",
      " -> SESCAM_9_0\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 45 glomerulis\n",
      " -> SAS_21937_001\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 17 glomerulis\n",
      " -> SAS_21883_001\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 11 glomerulis\n",
      " -> SAS_21891_001\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 13 glomerulis\n",
      " -> VUHSK_1912\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 114 glomerulis\n",
      " -> SESCAM_5_0\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 36 glomerulis\n",
      " -> SESCAM_2_0\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 23 glomerulis\n",
      " -> VUHSK_1992\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 40 glomerulis\n",
      " -> SAS_21930_001\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 5 glomerulis\n",
      " -> VUHSK_1622\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 44 glomerulis\n",
      " -> VUHSK_1352\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 22 glomerulis\n",
      " -> SAS_21942_001\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 15 glomerulis\n",
      " -> SESCAM_3_0\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 49 glomerulis\n",
      " -> VUHSK_1272\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 33 glomerulis\n",
      " -> VUHSK_1762\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 8 glomerulis\n",
      " -> VUHSK_1702\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 56 glomerulis\n",
      " -> SAS_21896_001\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 9 glomerulis\n",
      " -> SESCAM_6_0\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 52 glomerulis\n",
      " -> SESCAM_4_0\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 45 glomerulis\n",
      " -> SESCAM_8_0\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 25 glomerulis\n",
      " -> SAS_21915_001\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 12 glomerulis\n",
      " -> VUHSK_1832\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 36 glomerulis\n",
      " -> SAS_21924_001\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 6 glomerulis\n",
      " -> VUHSK_1432\n",
      "Setting patch size -1 and tile size -1\n",
      "Added 25 glomerulis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "turtle = py_wsi.Turtle(\n",
    "    DATA_PATH + \"extra/\", \n",
    "    DATA_PATH + \"extra/\",\n",
    "    \"extra\",\n",
    ")\n",
    "\n",
    "rles = {}\n",
    "\n",
    "for file in tqdm(turtle.files):\n",
    "    id_ = file[:-4]\n",
    "    print(f' -> {id_}')\n",
    "    \n",
    "    if os.path.exists(ANNOT_PATH + id_ + \".json\"):\n",
    "    \n",
    "        level_count, _, level_dims = turtle.retrieve_tile_dimensions(file, patch_size=-1)\n",
    "        shape = level_dims[level_count - 1]\n",
    "\n",
    "        img = turtle.retrieve_sample_patch(file, shape[0], level_count - 1)\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "\n",
    "        annot = json.load(open(ANNOT_PATH + id_ + \".json\", 'r'))\n",
    "\n",
    "        mask = np.zeros(shape[::-1], dtype=np.uint8)\n",
    "\n",
    "        added = 0\n",
    "        for info in annot:\n",
    "            poly = np.array(info['geometry']['coordinates'])\n",
    "            \n",
    "            try:\n",
    "                label = info['properties']['classification']['name']\n",
    "            except KeyError:\n",
    "                label = \"G\"\n",
    "                \n",
    "            if not ADD_FC and label == \"FC\":\n",
    "                continue\n",
    "                \n",
    "            poly = info['geometry']['coordinates']\n",
    "            try:\n",
    "                mask = cv2.fillPoly(mask, np.int32([poly]), True)\n",
    "            except ValueError:\n",
    "                poly = np.concatenate([np.array(poly[i]).squeeze() for i in range(len(poly))])\n",
    "                mask = cv2.fillPoly(mask, np.int32([poly]), True)\n",
    "            added += 1\n",
    "                \n",
    "        assert mask.max() == 1\n",
    "        \n",
    "        \n",
    "        print(f\"Added {added} glomerulis\")\n",
    "        \n",
    "        if PLOT:\n",
    "            print('plot')\n",
    "            fig = plot_contours_preds(img, mask, w=2, downsize=8)\n",
    "\n",
    "            w = 1000\n",
    "            h = int(w *  mask.shape[0] / mask.shape[1])\n",
    "            fig.update_layout(\n",
    "                autosize=False,\n",
    "                width=w,\n",
    "                height=h,\n",
    "            )\n",
    "\n",
    "            fig.show()\n",
    "\n",
    "            break\n",
    "            \n",
    "        if SAVE:\n",
    "            print(img.shape)\n",
    "            img = cv2.resize(\n",
    "                img,\n",
    "                (img.shape[1] // 2, img.shape[0] // 2),\n",
    "                interpolation=cv2.INTER_AREA,\n",
    "            )\n",
    "            print(img.shape)\n",
    "\n",
    "            if SAVE_TIFF:\n",
    "                if not os.path.exists(DATA_PATH + \"extra_tiff/\"):\n",
    "                    os.mkdir(DATA_PATH + \"extra_tiff/\")\n",
    "                tifffile.imsave(DATA_PATH + \"extra_tiff/\" + f\"{id_}.tiff\", img)\n",
    "\n",
    "            print(mask.shape)\n",
    "            mask = cv2.resize(\n",
    "                mask,\n",
    "                (mask.shape[1] // 2, mask.shape[0] // 2),\n",
    "                interpolation=cv2.INTER_NEAREST,\n",
    "            )\n",
    "            print(mask.shape)\n",
    "\n",
    "            rles[id_] = rle_encode_less_memory(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Saved masks to ../input/train_extra_fc.csv\n"
     ]
    }
   ],
   "source": [
    "df_annot_extra = pd.DataFrame.from_dict(rles, orient='index', columns=['encoding'])\n",
    "\n",
    "if SAVE and not PLOT:\n",
    "    name = \"train_extra.csv\" if not ADD_FC else \"train_extra_fc.csv\"\n",
    "    df_annot_extra.to_csv(DATA_PATH + name)\n",
    "    print(f'\\n -> Saved masks to {DATA_PATH + name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
