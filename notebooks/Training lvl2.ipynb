{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO :**\n",
    "- Recheck Augmentations\n",
    "- Recheck LAB normalization\n",
    "- sampler for faster convergence ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.append(\"../code/\")\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"1,0\"\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.main import k_fold\n",
    "\n",
    "from utils.logger import (\n",
    "    prepare_log_folder,\n",
    "    save_config,\n",
    "    create_logger,\n",
    "    update_overall_logs,\n",
    ")\n",
    "\n",
    "from params import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv(DATA_PATH + f\"HuBMAP-20-dataset_information.csv\")\n",
    "df_mask = pd.read_csv(DATA_PATH + \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = \"../logs/2021-04-05/4/\"  # b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"../logs/2021-04-05/4/boxes_1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.transforms import HE_preprocess_cls\n",
    "from data.dataset import TileClsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = df_mask['id'].values.tolist()\n",
    "# images = [img for j, img in enumerate(images) if (j % 5) == 0]\n",
    "\n",
    "dataset = TileClsDataset(images, SAVE_DIR, transforms=HE_preprocess_cls(visualize=True, size=128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, mask, y = dataset[0]\n",
    "print(f'Target : {int(y)} - max prob : {img[-1].max()}')\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img.numpy().transpose(1, 2, 0)[:, :, :3])\n",
    "plt.axis(False)\n",
    "plt.title('Image')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img.numpy().transpose(1, 2, 0)[:, :, -1])\n",
    "plt.axis(False)\n",
    "plt.title('Probabilities')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(mask.numpy())\n",
    "plt.axis(False)\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "truths = []\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    img, mask, y = dataset[i]\n",
    "    truths.append(y)\n",
    "    \n",
    "    prob = img[-1].numpy()\n",
    "    preds.append(prob[64, 64] > 0.4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(truths, np.array(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_zoo.models_cls import define_model_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_path = \"../logs/2021-04-05/4/\" + \"Unet_efficientnet-b1_0.pt\"\n",
    "model = define_model_cls('Unet', 'efficientnet-b1', cp_path=cp_path, in_channels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.rand(1, 4, 128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np  # noqa\n",
    "\n",
    "from torchcontrib.optim import SWA\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "from params import NUM_WORKERS\n",
    "from training.optim import define_loss, define_optimizer, prepare_for_loss\n",
    "\n",
    "\n",
    "def fit_cls(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    optimizer_name=\"Adam\",\n",
    "    loss_name=\"BCEWithLogitsLoss\",\n",
    "    activation=\"sigmoid\",\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    val_bs=32,\n",
    "    warmup_prop=0.1,\n",
    "    lr=1e-3,\n",
    "    swa_first_epoch=50,\n",
    "    verbose=1,\n",
    "    first_epoch_eval=0,\n",
    "    device=\"cuda\",\n",
    "    use_fp16=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Usual torch fit function.\n",
    "\n",
    "    Args:\n",
    "        model (torch model): Model to train.\n",
    "        train_dataset (torch dataset): Dataset to train with.\n",
    "        optimizer_name (str, optional): Optimizer name. Defaults to 'adam'.\n",
    "        loss_name (str, optional): Loss name. Defaults to 'BCEWithLogitsLoss'.\n",
    "        activation (str, optional): Activation function. Defaults to 'sigmoid'.\n",
    "        epochs (int, optional): Number of epochs. Defaults to 50.\n",
    "        batch_size (int, optional): Training batch size. Defaults to 32.\n",
    "        val_bs (int, optional): Validation batch size. Defaults to 32.\n",
    "        warmup_prop (float, optional): Warmup proportion. Defaults to 0.1.\n",
    "        lr (float, optional): Learning rate. Defaults to 1e-3.\n",
    "        swa_first_epoch (int, optional): Epoch to start applying SWA from. Defaults to 50.\n",
    "        verbose (int, optional): Period (in epochs) to display logs at. Defaults to 1.\n",
    "        first_epoch_eval (int, optional): Epoch to start evaluating at. Defaults to 0.\n",
    "        device (str, optional): Device for torch. Defaults to \"cuda\".\n",
    "        use_fp16 (bool, optional): Whether to use mixed precision. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        numpy array [len(val_dataset) x num_classes]: Last prediction on the validation data.\n",
    "        pandas dataframe: Training history.\n",
    "    \"\"\"\n",
    "\n",
    "    avg_val_loss = 0.0\n",
    "    history = None\n",
    "\n",
    "    if use_fp16:\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    optimizer = define_optimizer(optimizer_name, model.parameters(), lr=lr)\n",
    "    if swa_first_epoch <= epochs:\n",
    "        optimizer = SWA(optimizer)\n",
    "\n",
    "    loss_fct = define_loss(loss_name, device=device)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=val_bs,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    num_warmup_steps = int(warmup_prop * epochs * len(train_loader))\n",
    "    num_training_steps = int(epochs * len(train_loader))\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps, num_training_steps\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        avg_loss = 0\n",
    "\n",
    "        if epoch + 1 > swa_first_epoch:\n",
    "            optimizer.swap_swa_sgd()\n",
    "\n",
    "        for batch in train_loader:\n",
    "            x = batch[0].to(device).float()\n",
    "            y_batch = batch[2].float()\n",
    "\n",
    "            if use_fp16:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    y_pred = model(x)\n",
    "\n",
    "                    y_pred, y_batch = prepare_for_loss(y_pred, y_batch, loss_name, device=device)\n",
    "\n",
    "                    loss = loss_fct(y_pred, y_batch).mean()\n",
    "\n",
    "                    scaler.scale(loss).backward()\n",
    "\n",
    "                    avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "            else:\n",
    "                y_pred = model(x)\n",
    "\n",
    "                y_pred, y_batch = prepare_for_loss(y_pred, y_batch, loss_name, device=device)\n",
    "                loss = loss_fct(y_pred, y_batch).mean()\n",
    "\n",
    "                loss.backward()\n",
    "                avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "            scheduler.step()\n",
    "            for param in model.parameters():\n",
    "                param.grad = None\n",
    "\n",
    "        if epoch + 1 >= swa_first_epoch:\n",
    "            optimizer.update_swa()\n",
    "            optimizer.swap_swa_sgd()\n",
    "\n",
    "        model.eval()\n",
    "        avg_val_loss = 0.\n",
    "        preds, truths = [], []\n",
    "\n",
    "        if epoch + 1 >= first_epoch_eval:\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    x = batch[0].to(device).float()\n",
    "                    y_batch = batch[2].float()\n",
    "\n",
    "                    y_pred = model(x)\n",
    "\n",
    "                    y_pred, y_batch = prepare_for_loss(\n",
    "                        y_pred,\n",
    "                        y_batch,\n",
    "                        loss_name,\n",
    "                        device=device,\n",
    "                        train=False\n",
    "                    )\n",
    "\n",
    "                    loss = loss_fct(y_pred, y_batch).mean()\n",
    "                    avg_val_loss += loss / len(val_loader)\n",
    "\n",
    "                    if activation == \"sigmoid\":\n",
    "                        y_pred = torch.sigmoid(y_pred)\n",
    "                    elif activation == \"softmax\":\n",
    "                        y_pred = torch.softmax(y_pred, 2)\n",
    "\n",
    "                    preds.append(y_pred.cpu().numpy())\n",
    "                    truths.append(y_batch.cpu().numpy())\n",
    "\n",
    "        preds, truths = np.concatenate(preds), np.concatenate(truths)\n",
    "        acc = accuracy_score(truths, preds > 0.5)\n",
    "        \n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if (epoch + 1) % verbose == 0:\n",
    "            elapsed_time = elapsed_time * verbose\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1:02d}/{epochs:02d} \\t lr={lr:.1e}\\t t={elapsed_time:.0f}s\\t\"\n",
    "                f\"loss={avg_loss:.3f}\",\n",
    "                end=\"\\t\",\n",
    "            )\n",
    "            if epoch + 1 >= first_epoch_eval:\n",
    "                print(f\"val_loss={avg_val_loss:.3f} \\t acc={acc:.4f}\")\n",
    "            else:\n",
    "                print(\"\")\n",
    "\n",
    "    del val_loader, train_loader, y_pred, loss, x, y_batch\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return preds, truths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from params import DATA_PATH\n",
    "from training.train import fit\n",
    "from model_zoo.models import define_model\n",
    "from data.transforms import HE_preprocess\n",
    "from utils.metrics import tweak_threshold\n",
    "from training.predict import predict_entire_mask_downscaled\n",
    "from data.dataset import InMemoryTrainDataset, InferenceDataset\n",
    "from utils.torch import seed_everything, count_parameters, save_model_weights\n",
    "\n",
    "\n",
    "def train_cls(config, train_dataset, val_dataset, fold, log_folder=None):\n",
    "    \"\"\"\n",
    "    Trains and validate a model.\n",
    "\n",
    "    Args:\n",
    "        config (Config): Parameters.\n",
    "        dataset (torch Dataset): whole dataset InMemory\n",
    "        fold (int): Selected fold.\n",
    "        log_folder (None or str, optional): Folder to logs results to. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        SegmentationMeter: Meter.\n",
    "        pandas dataframe: Training history.\n",
    "    \"\"\"\n",
    "    seed_everything(config.seed)\n",
    "\n",
    "    model = define_model_cls(\n",
    "        config.decoder,\n",
    "        config.encoder,\n",
    "        num_classes=config.num_classes,\n",
    "        in_channels=config.in_channels,\n",
    "        cp_path=config.cp_folder + f\"{config.decoder}_{config.encoder}_{fold}.pt\"\n",
    "    ).to(config.device)\n",
    "    model.zero_grad()\n",
    "\n",
    "    n_parameters = count_parameters(model)\n",
    "\n",
    "    print(f\"    -> {n_parameters} trainable parameters\")\n",
    "    print(f\"    -> {len(train_dataset)} training tiles\")\n",
    "    print(f\"    -> {len(val_dataset)} validation tiles\\n\")\n",
    "\n",
    "    preds, truths = fit_cls(\n",
    "        model,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        optimizer_name=config.optimizer,\n",
    "        loss_name=config.loss,\n",
    "        activation=config.activation,\n",
    "        epochs=config.epochs,\n",
    "        batch_size=config.batch_size,\n",
    "        val_bs=config.val_bs,\n",
    "        lr=config.lr,\n",
    "        warmup_prop=config.warmup_prop,\n",
    "        swa_first_epoch=config.swa_first_epoch,\n",
    "        verbose=config.verbose,\n",
    "        first_epoch_eval=config.first_epoch_eval,\n",
    "        device=config.device,\n",
    "        use_fp16=config.use_fp16,\n",
    "    )\n",
    "\n",
    "    if config.save_weights and log_folder is not None:\n",
    "        name = f\"{config.encoder}_{fold}.pt\"\n",
    "        save_model_weights(\n",
    "            model,\n",
    "            name,\n",
    "            cp_folder=log_folder,\n",
    "        )\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return preds, truths\n",
    "\n",
    "\n",
    "def k_fold_cls(config, log_folder=None):\n",
    "    \"\"\"\n",
    "    Performs a patient grouped k-fold cross validation.\n",
    "    The following things are saved to the log folder : val predictions, histories\n",
    "\n",
    "    Args:\n",
    "        config (Config): Parameters.\n",
    "        log_folder (None or str, optional): Folder to logs results to. Defaults to None.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    images = pd.read_csv(f\"../input/train.csv\").id.unique()\n",
    "    \n",
    "    all_preds, all_truths = [], []\n",
    "\n",
    "    for i in config.selected_folds:\n",
    "        print(f\"\\n-------------   Fold {i + 1} / {config.nb_folds}  -------------\\n\")\n",
    "        \n",
    "        train_images = [img for j, img in enumerate(images) if (j % config.nb_folds) != i]\n",
    "        val_images = [img for j, img in enumerate(images) if (j % config.nb_folds) == i]\n",
    "        \n",
    "        train_dataset = TileClsDataset(\n",
    "            train_images, \n",
    "            config.tile_dir, \n",
    "            transforms=HE_preprocess_cls(size=config.tile_size)\n",
    "        )\n",
    "        \n",
    "        val_dataset = TileClsDataset(\n",
    "            val_images, \n",
    "            config.tile_dir, \n",
    "            transforms=HE_preprocess_cls(size=config.tile_size, augment=False)\n",
    "        )\n",
    "\n",
    "        preds, truths = train_cls(config, train_dataset, val_dataset, i, log_folder=log_folder)\n",
    "        all_preds.append(preds)\n",
    "        all_truths.append(truths)\n",
    "        \n",
    "    preds = np.concatenate(all_preds)\n",
    "    truths = np.concatenate(all_truths)\n",
    "    \n",
    "    acc = accuracy_score(truths, preds > 0.5)\n",
    "    print(f'\\n -> Accuracy CV : {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = {\n",
    "    \"resnet18\": 64,\n",
    "    \"resnet34\": 32, \n",
    "    \"resnext50_32x4d\": 32, \n",
    "    \"se_resnext50_32x4d\": 32,\n",
    "    \"efficientnet-b0\": 32,\n",
    "    \"efficientnet-b1\": 32,\n",
    "    \"efficientnet-b2\": 32,\n",
    "    \"efficientnet-b3\": 32,\n",
    "    \"efficientnet-b4\": 32,\n",
    "    \"efficientnet-b5\": 16,\n",
    "    \"efficientnet-b6\": 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    save_weights = True\n",
    "    \n",
    "    # Images    \n",
    "    tile_dir = \"../logs/2021-04-05/4/boxes_1/\"\n",
    "    tile_size = 128\n",
    "\n",
    "    # k-fold\n",
    "    nb_folds = 5\n",
    "    selected_folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "    # Model\n",
    "    encoder = \"efficientnet-b1\"  # \"resnet18\" \"resnext50_32x4d\", \"resnet34\", \"efficientnet-b5\"\n",
    "    decoder = \"Unet\"  # \"Unet\", \"DeepLabV3Plus\"\n",
    "    num_classes = 1\n",
    "    in_channels = 4\n",
    "    cp_folder = \"../logs/2021-04-05/4/\"  # b1\n",
    "\n",
    "    # Training\n",
    "    loss = \"BCEWithLogitsLoss\"  # \"SoftDiceLoss\" / \"BCEWithLogitsLoss\"  / \"lovasz\"\n",
    "    activation = \"none\" if loss == \"lovasz\" else \"sigmoid\"\n",
    "\n",
    "    optimizer = \"Adam\"\n",
    "    \n",
    "    batch_size = BATCH_SIZES[encoder]\n",
    "        \n",
    "    epochs = 15\n",
    "\n",
    "    lr = 1e-3\n",
    "    swa_first_epoch = 20\n",
    "\n",
    "    warmup_prop = 0.05\n",
    "    val_bs = batch_size * 2\n",
    "\n",
    "    first_epoch_eval = 0\n",
    "    \n",
    "    use_fp16 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    config_df = save_config(Config, log_folder + \"config.json\")\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "metrics = k_fold_cls(Config, log_folder=log_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
