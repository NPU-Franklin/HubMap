{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install segmentation-models-pytorch\n",
    "# !pip install torchcontrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "from data.dataset import TileDataset, PredictFromImgDataset\n",
    "from data.transforms import HE_preprocess\n",
    "from model_zoo.models import define_model\n",
    "from utils.plots import plot_global_pred, plot_thresh_scores\n",
    "from utils.save import save_as_jit\n",
    "from training.predict import predict_entire_mask\n",
    "from training.train import fit\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 256   #the size of tiles\n",
    "reduce_fac = 4 #reduce the original images by 4 times\n",
    "\n",
    "\n",
    "MASKS = '../input/hubmap-kidney-segmentation/train.csv'\n",
    "DATA = '../input/hubmap-kidney-segmentation/train/'\n",
    "ZIP_TRAIN = f'../input/hubmap-kidney-segmentation/train_{tile_size}_red_{reduce_fac}.zip'\n",
    "ZIP_MASKS = f'../input/hubmap-kidney-segmentation/masks_{tile_size}_red_{reduce_fac}.zip'\n",
    "\n",
    "IMG_FOLDER = f'../input/hubmap-kidney-segmentation/train_{tile_size}_red_{reduce_fac}/'\n",
    "MSK_FOLDER = f'../input/hubmap-kidney-segmentation/masks_{tile_size}_red_{reduce_fac}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split by image id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mask = pd.read_csv(MASKS)\n",
    "slide_ids = df_mask.id.unique().tolist()\n",
    "\n",
    "with zipfile.ZipFile(ZIP_TRAIN, 'r') as img_arch, \\\n",
    "     zipfile.ZipFile(ZIP_MASKS, 'r') as msk_arch:\n",
    "    fnames = img_arch.namelist()\n",
    "    \n",
    "df_images = pd.DataFrame()\n",
    "df_images['tile_name'] = fnames\n",
    "df_images['fold'] = df_images['tile_name'].apply(lambda f: slide_ids.index(f.split(\"_\", 1)[0]))\n",
    "\n",
    "fold_mapper = {0 : \"0_1\", 1 : \"0_1\",\n",
    "               2 : \"2_3\", 3 : \"2_3\",\n",
    "               4 : \"4_5\", 5 : \"4_5\",\n",
    "               6 : \"6_7\", 7 : \"6_7\",}\n",
    "\n",
    "df_images['4fold'] = df_images['fold'].map(fold_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIZ and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of train images with masks\n",
    "viz_ds = TileDataset(df_images,\n",
    "                     IMG_FOLDER,\n",
    "                     MSK_FOLDER,\n",
    "                     transforms=HE_preprocess(augment=True, visualize=True))\n",
    "viz_dl = DataLoader(viz_ds, batch_size=64,shuffle=False,num_workers=1)\n",
    "imgs,masks = next(iter(viz_dl))\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "for i,(img,mask) in enumerate(zip(imgs,masks)):\n",
    "    img = img.permute(1,2,0).numpy()#.astype(np.uint8)\n",
    "    plt.subplot(8,8,i+1)\n",
    "    plt.imshow(img,vmin=0,vmax=255\n",
    "              )\n",
    "    plt.imshow(mask.squeeze().numpy(), alpha=0.5)\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(wspace=None, hspace=None)\n",
    "    \n",
    "# del viz_ds, viz_dl, imgs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder = \"se_resnext50_32x4d\"\n",
    "decoder = \"Unet\"\n",
    "plot_global = False\n",
    "cv_column = \"4fold\"\n",
    "\n",
    "cv_scores = []\n",
    "for fold_nb in df_images[cv_column].unique():\n",
    "    print(\"FOLD :\", fold_nb)\n",
    "#     if fold_nb <3:\n",
    "#         continue\n",
    "    train_df = df_images[df_images[cv_column]!=fold_nb].reset_index()\n",
    "    val_df = df_images[df_images[cv_column]==fold_nb].reset_index()\n",
    "    mask_names = val_df.tile_name.apply(lambda x: x.split(\"_\")[0]).unique()\n",
    "    \n",
    "    train_dataset = TileDataset(train_df,\n",
    "                                IMG_FOLDER, MSK_FOLDER,\n",
    "                                transforms=HE_preprocess(augment=True, visualize=False))\n",
    "    val_dataset = TileDataset(val_df,\n",
    "                              IMG_FOLDER, MSK_FOLDER,\n",
    "                              transforms=HE_preprocess(augment=False, visualize=False))\n",
    "\n",
    "    model = define_model(decoder, encoder, num_classes=1, activation=None).to(\"cuda\")\n",
    "    meter, history = fit(model,\n",
    "                         train_dataset=train_dataset,\n",
    "                         val_dataset=val_dataset,\n",
    "                         epochs=50,\n",
    "                         loss_name=\"BCEWithLogitsLoss\",\n",
    "                         swa_first_epoch = 40,\n",
    "                         batch_size=32\n",
    "                        )\n",
    "    cv_scores.append(history.dice.values[-1])\n",
    "    px.line(history, x='epoch', y='dice').show()\n",
    "    \n",
    "    saving_path = \"../models/\"\n",
    "    model_name = f\"{encoder}_{decoder}_{tile_size}_{reduce_fac}_fold{fold_nb}\"\n",
    "#     torch.save(model.state_dict(), os.path.join(saving_path, model_name+\".pt\")\n",
    "    save_as_jit(model, saving_path, model_name, train_img_size=tile_size)\n",
    "    if plot_global:\n",
    "        for mask_name in mask_names:\n",
    "            print(f\"predicting global image {mask_name}...\")\n",
    "            predict_dataset = PredictFromImgDataset(f'../input/hubmap-kidney-segmentation/train/{mask_name}.tiff',\n",
    "                                                mask_name = mask_name,\n",
    "                                                overlap_factor=4,\n",
    "                                                reduce_factor=reduce_fac,\n",
    "                                                transforms=HE_preprocess(augment=False, visualize=False))\n",
    "\n",
    "            global_pred = predict_entire_mask(predict_dataset,\n",
    "                                          model,\n",
    "                                          batch_size = 32)\n",
    "            plot_global_pred(mask=predict_dataset.mask, pred=global_pred>0)\n",
    "            thresholds, scores = plot_thresh_scores(mask=predict_dataset.mask, pred=global_pred)\n",
    "            max_score_pos = np.argmax(scores)\n",
    "            print(f\"Maximum dice: {scores[max_score_pos]} with thresh {thresholds[max_score_pos]}\")\n",
    "\n",
    "print(f\"Average CV : {np.mean(cv_scores)} (std : {np.std(cv_scores)})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
